services:
  postgres:
    image: postgres:latest
    container_name: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: financial
      POSTGRES_INITDB_ARGS: "--encoding=UTF8"
    ports:
      - "5432:5432"
    volumes:
      - ./sql/postgres.sql:/docker-entrypoint-initdb.d/postgres.sql
    command: >
      postgres
      -c wal_level=logical
      -c max_replication_slots=4
      -c max_wal_senders=4
      -c shared_preload_libraries=pg_stat_statements
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d financial"]
      interval: 10s
      timeout: 5s
      retries: 5

  zookeeper-kafka:
    platform: linux/amd64
    image: confluentinc/cp-zookeeper:7.2.15
    container_name: zookeeper-kafka
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  broker-kafka:
    image: confluentinc/cp-kafka:7.2.15
    container_name: broker-kafka
    depends_on:
      - zookeeper-kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-kafka:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "kafka-topics", "--list", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5

  schema-registry:
    platform: linux/amd64
    image: confluentinc/cp-schema-registry:7.6.1
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker-kafka
    ports:
      - "8084:8084"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker-kafka:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8084
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8084/subjects"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  ksqldb-server:
    platform: linux/amd64
    image: confluentinc/cp-ksqldb-server:7.6.1
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - broker-kafka
      - connect
    ports:
      - "8087:8087"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_BOOTSTRAP_SERVERS: "broker-kafka:29092"
      KSQL_HOST_NAME: ksqldb-server
      KSQL_LISTENERS: "http://0.0.0.0:8087"
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8084"
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      KSQL_KSQL_CONNECT_URL: "http://connect:8085"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'

  control-center-kafka:
    platform: linux/amd64
    image: confluentinc/cp-enterprise-control-center:latest
    hostname: control-center
    container_name: control-center-kafka
    depends_on:
      - broker-kafka
      - schema-registry
      - connect
      - ksqldb-server
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker-kafka:29092'
      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'connect:8085'
      CONTROL_CENTER_CONNECT_HEALTHCHECK_ENDPOINT: '/connectors'
      CONTROL_CENTER_KSQL_KSQLDB1_URL: "http://ksqldb-server:8087"
      CONTROL_CENTER_KSQL_KSQLDB1_ADVERTISED_URL: "http://localhost:8087"
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8084"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021

  connect:
    platform: linux/amd64
    image: cnfldemos/cp-server-connect-datagen:0.5.3-7.1.0
    hostname: connect
    container_name: connect
    depends_on:
      - broker-kafka
      - schema-registry
    ports:
      - "8085:8085"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker-kafka:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8084
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.6.1.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR

  curl-kafka-connect:
    image: curlimages/curl:latest
    container_name: curl-kafka-connect
    depends_on:
      - debezium
      - postgres
    entrypoint: >
      sh -c "
      echo 'Waiting for Debezium to be ready...';
      while ! curl -s debezium:8083; do sleep 20; done;
      echo 'Debezium is ready. Creating connector...';
      curl -X POST -H 'Accept:application/json' -H 'Content-Type:application/json' debezium:8083/connectors/ -d '
      {
        \"name\": \"postgres-connector\",
        \"config\": {
          \"connector.class\": \"io.debezium.connector.postgresql.PostgresConnector\",
          \"database.user\": \"postgres\",
          \"database.dbname\": \"financial\",
          \"topic.prefix\": \"financial\",
          \"tasks.max\": \"10\",
          \"database.hostname\": \"postgres\",
          \"database.password\": \"postgres\",
          \"schema.include.list\": \"public\",
          \"plugin.name\": \"pgoutput\",
          \"database.port\": \"5432\",
          \"database.server.id\": \"1001\"
        }
      }';
      echo 'Connector created. Verifying...';
      curl -s debezium:8083/connectors/postgres-connector | grep '\"name\":\"postgres-connector\"';
      if [ $? -eq 0 ]; then
        echo 'Test passed: Connector created successfully.';
      else
        echo 'Test failed: Connector creation failed.';
        exit 1;
      fi
      "

  debezium:
    platform: linux/amd64
    image: debezium/connect:2.7.3.Final
    restart: always
    container_name: debezium
    hostname: debezium
    depends_on:
      - broker-kafka
    ports:
      - '8083:8083'
    environment:
      BOOTSTRAP_SERVERS: 'broker-kafka:29092'
      GROUP_ID: 'debezium'
      CONFIG_STORAGE_TOPIC: 'debezium-connect-configs'
      STATUS_STORAGE_TOPIC: 'debezium-connect-status'
      OFFSET_STORAGE_TOPIC: 'debezium-connect-offsets'
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      ENABLE_DEBEZIUM_SCRIPTING: 'true'
      CONNECT_TOPIC_CREATION_ENABLE: 'true'
      OFFSET_FLUSH_INTERVAL_MS: 120000
      OFFSET_FLUSH_TIMEOUT_MS: 60000
      PRODUCER_ACKS: all
      PRODUCER_BATCH_SIZE: 65536
      PRODUCER_BUFFER_MEMORY: 33554432
      PRODUCER_COMPRESSION_TYPE: lz4
      CONSUMER_ALLOW_AUTO_CREATE_TOPICS: true
      CONSUMER_AUTO_OFFSET_RESET: latest

  debezium-ui:
    platform: linux/amd64
    image: debezium/debezium-ui:latest
    restart: always
    container_name: debezium-ui
    hostname: debezium-ui
    depends_on:
      - debezium
    ports:
      - '8080:8080'
    environment:
      KAFKA_CONNECT_URIS: 'http://debezium:8083'

  clickhouse-server:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse-server
    ports:
      - "8123:8123"
      - "9000:9000"
    environment:
      - CLICKHOUSE_DB=default
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    volumes:
      - ./sql/clickhouse.sql:/docker-entrypoint-initdb.d/clickhouse.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "curl -sSf http://localhost:8123/ping || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "5173:5173"
    environment:
      - NODE_ENV=development
    volumes:
      - ../frontend:/app
      - /app/node_modules
    depends_on:
      - clickhouse-server
    healthcheck:
      test: ["CMD-SHELL", "curl -sSf http://localhost:5173 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  financial_data:
  financial_network:

networks:
  default:
    name: financial_network
